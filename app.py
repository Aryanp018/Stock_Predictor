{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1ac9e-146f-42b4-a331-1acf0c9f814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import ta\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# StockPredictor class (copied from your notebook)\n",
    "class StockPredictor:\n",
    "    def __init__(self, stock_symbol, api_key, look_back=60, prediction_days=1, max_retries=3):\n",
    "        self.stock_symbol = stock_symbol.upper()\n",
    "        self.api_key = api_key\n",
    "        self.look_back = look_back\n",
    "        self.prediction_days = prediction_days\n",
    "        self.max_retries = max_retries\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        self.data = None\n",
    "        self.models = {}\n",
    "        \n",
    "    def get_stock_data(self):\n",
    "        retries = 0\n",
    "        while retries < self.max_retries:\n",
    "            try:\n",
    "                ts = TimeSeries(key=self.api_key, output_format='pandas')\n",
    "                data, meta_data = ts.get_daily(symbol=self.stock_symbol, outputsize='full')\n",
    "                data = data.rename(columns={\n",
    "                    '1. open': 'Open',\n",
    "                    '2. high': 'High',\n",
    "                    '3. low': 'Low',\n",
    "                    '4. close': 'Close',\n",
    "                    '5. volume': 'Volume'\n",
    "                })\n",
    "                data = data.sort_index()\n",
    "                data = data.loc['2015-01-01':datetime.today().strftime('%Y-%m-%d')]\n",
    "                if data.empty:\n",
    "                    raise ValueError(f\"No data found for {self.stock_symbol}\")\n",
    "                self.data = data\n",
    "                logging.info(f\"Successfully downloaded data for {self.stock_symbol}\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                retries += 1\n",
    "                logging.warning(f\"Attempt {retries} failed: {str(e)}\")\n",
    "                if retries == self.max_retries:\n",
    "                    logging.error(f\"Error fetching data for {self.stock_symbol} after {self.max_retries} attempts\")\n",
    "                    return False\n",
    "                time.sleep(2 ** retries)\n",
    "                \n",
    "    def add_technical_indicators(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        df = self.data.copy()\n",
    "        try:\n",
    "            df['RSI'] = ta.momentum.RSIIndicator(df['Close']).rsi()\n",
    "            df['MA20'] = ta.trend.SMAIndicator(df['Close'], window=20).sma_indicator()\n",
    "            df['MA50'] = ta.trend.SMAIndicator(df['Close'], window=50).sma_indicator()\n",
    "            bb = ta.volatility.BollingerBands(df['Close'])\n",
    "            df['BB_upper'] = bb.bollinger_hband()\n",
    "            df['BB_middle'] = bb.bollinger_mavg()\n",
    "            df['BB_lower'] = bb.bollinger_lband()\n",
    "            df = df.dropna()\n",
    "            self.data = df\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error adding technical indicators: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def prepare_lstm_data(self):\n",
    "        prices = self.data['Close'].values\n",
    "        scaled_data = self.scaler.fit_transform(prices.reshape(-1, 1))\n",
    "        \n",
    "        X, y = [], []\n",
    "        for i in range(self.look_back, len(scaled_data) - self.prediction_days):\n",
    "            X.append(scaled_data[i-self.look_back:i])\n",
    "            y.append(scaled_data[i:i+self.prediction_days]) \n",
    "        \n",
    "        X, y = np.array(X), np.array(y)\n",
    "        train_size = int(len(X) * 0.8)\n",
    "        return (X[:train_size], y[:train_size], \n",
    "                X[train_size:], y[train_size:], scaled_data)\n",
    "\n",
    "    def create_lstm_model(self):\n",
    "        from tensorflow.keras.optimizers import Adam\n",
    "        model = Sequential([\n",
    "            LSTM(100, return_sequences=True, input_shape=(self.look_back, 1)),\n",
    "            Dropout(0.3),\n",
    "            LSTM(100),\n",
    "            Dropout(0.3),\n",
    "            Dense(50),\n",
    "            Dense(self.prediction_days)\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        return model\n",
    "\n",
    "    def train_models(self):\n",
    "        if self.data is None:\n",
    "            return None, None, None, None\n",
    "            \n",
    "        import tensorflow as tf\n",
    "        import random\n",
    "        np.random.seed(42)\n",
    "        tf.random.set_seed(42)\n",
    "        random.seed(42)\n",
    "\n",
    "        features = ['Close', 'RSI', 'MA20', 'MA50', 'BB_upper', 'BB_lower']\n",
    "        X_lstm_train, y_lstm_train, X_lstm_test, y_lstm_test, scaled_data = self.prepare_lstm_data()\n",
    "        \n",
    "        self.models['lstm'] = self.create_lstm_model()\n",
    "        self.models['lstm'].fit(X_lstm_train, y_lstm_train, epochs=50, \n",
    "                              batch_size=32, validation_split=0.1, verbose=0)\n",
    "        \n",
    "        X = self.data[features].values\n",
    "        y = self.data['Close'].shift(-self.prediction_days).values\n",
    "        mask = ~np.isnan(y)\n",
    "        X, y = X[mask], y[mask]\n",
    "        \n",
    "        total_samples = len(scaled_data) - self.look_back - self.prediction_days + 1\n",
    "        train_size = int(total_samples * 0.8)\n",
    "        \n",
    "        rf_gb_scaler = MinMaxScaler()\n",
    "        X_scaled = rf_gb_scaler.fit_transform(X)\n",
    "        \n",
    "        X_train, X_test = X_scaled[:train_size], X_scaled[train_size:train_size + len(X_lstm_test)]\n",
    "        y_train, y_test = y[:train_size], y[train_size:train_size + len(X_lstm_test)]\n",
    "        \n",
    "        self.models['rf'] = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "        self.models['rf'].fit(X_train, y_train)\n",
    "        \n",
    "        self.models['gb'] = GradientBoostingRegressor(n_estimators=200, max_depth=5, learning_rate=0.05, random_state=42)\n",
    "        self.models['gb'].fit(X_train, y_train)\n",
    "        \n",
    "        return X_lstm_test, y_lstm_test, X_test, y_test\n",
    "\n",
    "    def predict(self, X_lstm_test, X_test):\n",
    "        lstm_pred = self.models['lstm'].predict(X_lstm_test, verbose=0)\n",
    "        rf_pred = self.models['rf'].predict(X_test)\n",
    "        gb_pred = self.models['gb'].predict(X_test)\n",
    "        \n",
    "        lstm_pred_inv = self.scaler.inverse_transform(lstm_pred[:, -1].reshape(-1, 1))\n",
    "        lstm_pred_inv = lstm_pred_inv.flatten()\n",
    "        \n",
    "        lstm_rmse, rf_rmse, gb_rmse = 11.73, 72.60, 74.10\n",
    "        total_inverse_rmse = (1/lstm_rmse) + (1/rf_rmse) + (1/gb_rmse)\n",
    "        lstm_weight = (1/lstm_rmse) / total_inverse_rmse\n",
    "        rf_weight = (1/rf_rmse) / total_inverse_rmse\n",
    "        gb_weight = (1/gb_rmse) / total_inverse_rmse\n",
    "        \n",
    "        ensemble_pred = (lstm_weight * lstm_pred_inv + rf_weight * rf_pred + gb_weight * gb_pred)\n",
    "        return ensemble_pred, lstm_pred_inv, rf_pred, gb_pred\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"ðŸ“ˆ Stock Price Predictor\")\n",
    "st.write(\"Enter a stock symbol and Alpha Vantage API key to get a 1-day-ahead price prediction.\")\n",
    "\n",
    "# Sidebar instructions\n",
    "st.sidebar.markdown(\"\"\"\n",
    "### How to Use\n",
    "1. Get a free API key from [Alpha Vantage](https://www.alphavantage.co).\n",
    "2. Enter a stock symbol (e.g., NVDA, AAPL) and your API key.\n",
    "3. Click \"Predict\" to see results in ~2â€“5 minutes.\n",
    "\"\"\")\n",
    "\n",
    "# User inputs\n",
    "symbol = st.text_input(\"Stock Symbol (e.g., NVDA, AAPL):\", \"NVDA\")\n",
    "api_key = st.text_input(\"Alpha Vantage API Key:\", type=\"password\")\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    if not symbol or not api_key:\n",
    "        st.error(\"Please provide both a stock symbol and API key.\")\n",
    "    else:\n",
    "        with st.spinner(\"Fetching data and running models...\"):\n",
    "            try:\n",
    "                # Progress bar\n",
    "                progress = st.progress(0)\n",
    "                predictor = StockPredictor(symbol, api_key, prediction_days=1)\n",
    "                \n",
    "                # Step 1: Fetch data\n",
    "                progress.progress(0.25)\n",
    "                if not predictor.get_stock_data():\n",
    "                    st.error(f\"Failed to fetch data for {symbol}. Check symbol or API key.\")\n",
    "                    st.stop()\n",
    "                \n",
    "                # Step 2: Add indicators\n",
    "                progress.progress(0.5)\n",
    "                df = predictor.add_technical_indicators()\n",
    "                if df is None:\n",
    "                    st.error(\"Failed to add technical indicators.\")\n",
    "                    st.stop()\n",
    "                \n",
    "                # Step 3: Train models\n",
    "                progress.progress(0.75)\n",
    "                X_lstm_test, y_lstm_test, X_test, y_test = predictor.train_models()\n",
    "                if X_lstm_test is None:\n",
    "                    st.error(\"Failed to train models.\")\n",
    "                    st.stop()\n",
    "                \n",
    "                # Step 4: Predict\n",
    "                progress.progress(1.0)\n",
    "                ensemble_pred, lstm_pred, rf_pred, gb_pred = predictor.predict(X_lstm_test, X_test)\n",
    "                y_test_inv = predictor.scaler.inverse_transform(y_lstm_test[:, -1].reshape(-1, 1)).flatten()\n",
    "                \n",
    "                # Calculate RMSE\n",
    "                rmse_results = {}\n",
    "                for name, pred in [('Ensemble', ensemble_pred), ('LSTM', lstm_pred), \n",
    "                                 ('RF', rf_pred), ('GB', gb_pred)]:\n",
    "                    rmse = np.sqrt(mean_squared_error(y_test_inv, pred))\n",
    "                    rmse_results[name] = rmse\n",
    "                \n",
    "                # Display results\n",
    "                st.success(\"Prediction completed!\")\n",
    "                st.subheader(\"1-Day-Ahead Closing Price Predictions\")\n",
    "                st.write(f\"**Ensemble**: ${ensemble_pred[-1]:.2f}\")\n",
    "                st.write(f\"**LSTM**: ${lstm_pred[-1]:.2f}\")\n",
    "                st.write(f\"**Random Forest**: ${rf_pred[-1]:.2f}\")\n",
    "                st.write(f\"**Gradient Boosting**: ${gb_pred[-1]:.2f}\")\n",
    "                \n",
    "                st.subheader(\"Model Performance (RMSE)\")\n",
    "                for name, rmse in rmse_results.items():\n",
    "                    st.write(f\"**{name}**: {rmse:.2f}\")\n",
    "                \n",
    "                # Plot\n",
    "                st.subheader(\"Prediction vs. Actual Prices\")\n",
    "                fig = plt.figure(figsize=(15, 7))\n",
    "                plt.plot(df.index[-len(y_test):], y_test_inv, label='Actual')\n",
    "                plt.plot(df.index[-len(y_test):], ensemble_pred, label='Ensemble')\n",
    "                plt.plot(df.index[-len(y_test):], lstm_pred, label='LSTM')\n",
    "                plt.plot(df.index[-len(y_test):], rf_pred, label='Random Forest')\n",
    "                plt.plot(df.index[-len(y_test):], gb_pred, label='Gradient Boosting')\n",
    "                plt.title(f'{symbol} Stock Price Prediction (1-Day Ahead)')\n",
    "                plt.xlabel('Date')\n",
    "                plt.ylabel('Price')\n",
    "                plt.legend()\n",
    "                plt.xticks(rotation=45)\n",
    "                st.pyplot(fig)\n",
    "                \n",
    "            except Exception as e:\n",
    "                st.error(f\"Error: {str(e)}. Check your API key, symbol, or try again later.\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "**Note**: This app uses the Alpha Vantage API (free tier: 5 requests/min). Predictions may take a few minutes due to model training.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
